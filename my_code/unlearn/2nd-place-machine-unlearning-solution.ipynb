{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103dea5d",
   "metadata": {
    "papermill": {
     "duration": 0.004185,
     "end_time": "2023-12-01T08:22:37.751272",
     "exception": false,
     "start_time": "2023-12-01T08:22:37.747087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# For-Debugging Notebook\n",
    "\n",
    "This notebook is a notebook for debugging `unlearning` function, based on the following notebook:\n",
    "- https://www.kaggle.com/code/eleni30fillou/run-unlearn-finetune\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. implement your `unlearning` function;\n",
    "2. turn on `internet on` in the right panel;\n",
    "3. set the variable `USE_MOCK` to `True` in the 2nd code cell;\n",
    "4. (Optional) modity other parameters in the same cell like `n_checkpoints`;\n",
    "5. if your codes work,\n",
    "   - turn off `internet on` in the right panel;\n",
    "   - set the variable `USE_MOCK` to `False` in the 2nd code cell;\n",
    "   - save the notebook;\n",
    "   - and submit!\n",
    "\n",
    "## Updates\n",
    "- Ver.5:\n",
    "  - add a stopwatch decorator\n",
    "  - make `unlearning` return a updated model\n",
    "- Ver.4: fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5f8deb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:37.760814Z",
     "iopub.status.busy": "2023-12-01T08:22:37.760134Z",
     "iopub.status.idle": "2023-12-01T08:22:42.013681Z",
     "shell.execute_reply": "2023-12-01T08:22:42.012757Z"
    },
    "papermill": {
     "duration": 4.261173,
     "end_time": "2023-12-01T08:22:42.016280",
     "exception": false,
     "start_time": "2023-12-01T08:22:37.755107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3ddfed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.026489Z",
     "iopub.status.busy": "2023-12-01T08:22:42.026027Z",
     "iopub.status.idle": "2023-12-01T08:22:42.035857Z",
     "shell.execute_reply": "2023-12-01T08:22:42.035040Z"
    },
    "papermill": {
     "duration": 0.016667,
     "end_time": "2023-12-01T08:22:42.037795",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.021128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e4bd066b970>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(3047)\n",
    "\n",
    "Gr = torch.Generator()\n",
    "Gr.manual_seed(20)\n",
    "\n",
    "Gf = torch.Generator()\n",
    "Gf.manual_seed(30)\n",
    "\n",
    "Gv = torch.Generator()\n",
    "Gv.manual_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8a45ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.048018Z",
     "iopub.status.busy": "2023-12-01T08:22:42.047759Z",
     "iopub.status.idle": "2023-12-01T08:22:42.053164Z",
     "shell.execute_reply": "2023-12-01T08:22:42.052382Z"
    },
    "papermill": {
     "duration": 0.011941,
     "end_time": "2023-12-01T08:22:42.055023",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.043082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mock setting\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "import tqdm\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "USE_MOCK: bool = False\n",
    "\n",
    "if USE_MOCK:\n",
    "    logging.warning('Running with Mock')\n",
    "    logging.warning('In this mode, internet access may be required.')\n",
    "\n",
    "    # The number of checkpoints in this mode.\n",
    "    # NOTE: 512 checkpoints are required in this competition.\n",
    "    n_checkpoints = 5\n",
    "    \n",
    "    # The directory for a dataset and a pretrained model\n",
    "    mock_dir = './mock'\n",
    "    mock_model_path = os.path.join(mock_dir, \"weights_resnet18_cifar10.pth\")\n",
    "    os.makedirs(mock_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b33df8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.063613Z",
     "iopub.status.busy": "2023-12-01T08:22:42.063334Z",
     "iopub.status.idle": "2023-12-01T08:22:42.067238Z",
     "shell.execute_reply": "2023-12-01T08:22:42.066565Z"
    },
    "papermill": {
     "duration": 0.010172,
     "end_time": "2023-12-01T08:22:42.069032",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.058860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It's really important to add an accelerator to your notebook, as otherwise the submission will fail.\n",
    "# We recomment using the P100 GPU rather than T4 as it's faster and will increase the chances of passing the time cut-off threshold.\n",
    "\n",
    "if DEVICE != 'cuda':\n",
    "    raise RuntimeError('Make sure you have added an accelerator to your notebook; the submission will fail otherwise!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2077f335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.077926Z",
     "iopub.status.busy": "2023-12-01T08:22:42.077658Z",
     "iopub.status.idle": "2023-12-01T08:22:42.095485Z",
     "shell.execute_reply": "2023-12-01T08:22:42.094676Z"
    },
    "papermill": {
     "duration": 0.024366,
     "end_time": "2023-12-01T08:22:42.097262",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.072896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for loading the hidden dataset.\n",
    "\n",
    "if USE_MOCK:\n",
    "    \n",
    "    class DatasetWrapper(Dataset):\n",
    "        \n",
    "        def __init__(self, ds: Dataset):\n",
    "            self._ds = ds\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self._ds)\n",
    "    \n",
    "        def __getitem__(self, index):\n",
    "            item = self._ds[index]\n",
    "            result = {\n",
    "                'image': item[0],\n",
    "                'image_id': index,\n",
    "                'age_group': item[1],\n",
    "                'age': item[1],\n",
    "                'person_id': index,\n",
    "            }\n",
    "            return result\n",
    "    \n",
    "    def get_dataset(batch_size, retain_ratio=0.98, thinning_param: int=1, root=mock_dir) -> tuple[DataLoader, DataLoader, DataLoader]:\n",
    "        \n",
    "        # utils\n",
    "        normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "        # create dataset\n",
    "        train_ds = DatasetWrapper(torchvision.datasets.CIFAR10(root=mock_dir, train=True, download=True, transform=normalize))\n",
    "        retain_ds = Subset(train_ds, range(0, int(len(train_ds)*retain_ratio), thinning_param))\n",
    "        forget_ds = Subset(train_ds, range(int(len(train_ds)*retain_ratio), len(train_ds), thinning_param))\n",
    "        val_ds = DatasetWrapper(torchvision.datasets.CIFAR10(root=mock_dir, train=False, download=True, transform=normalize))\n",
    "\n",
    "        retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True)\n",
    "        forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True)\n",
    "        validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        return retain_loader, forget_loader, validation_loader\n",
    "    \n",
    "    # For test\n",
    "#     for sample in get_dataset(3)[0]:\n",
    "#         print(sample)\n",
    "#         break\n",
    "    \n",
    "else:\n",
    "    def load_example(df_row):\n",
    "        image = torchvision.io.read_image(df_row['image_path'])\n",
    "        result = {\n",
    "            'image': image,\n",
    "            'image_id': df_row['image_id'],\n",
    "            'age_group': df_row['age_group'],\n",
    "            'age': df_row['age'],\n",
    "            'person_id': df_row['person_id']\n",
    "        }\n",
    "        return result\n",
    "\n",
    "\n",
    "    class HiddenDataset(Dataset):\n",
    "        '''The hidden dataset.'''\n",
    "        def __init__(self, split='train'):\n",
    "            super().__init__()\n",
    "            self.examples = []\n",
    "\n",
    "            df = pd.read_csv(f'/kaggle/input/neurips-2023-machine-unlearning/{split}.csv')\n",
    "            df['image_path'] = df['image_id'].apply(lambda x: os.path.join('/kaggle/input/neurips-2023-machine-unlearning/', 'images', x.split('-')[0], x.split('-')[1] + '.png'))\n",
    "            df = df.sort_values(by='image_path')\n",
    "            df.apply(lambda row: self.examples.append(load_example(row)), axis=1)\n",
    "            if len(self.examples) == 0:\n",
    "                raise ValueError('No examples.')\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.examples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            example = self.examples[idx]\n",
    "            image = example['image']\n",
    "            image = image.to(torch.float32)\n",
    "            example['image'] = image\n",
    "            return example\n",
    "\n",
    "\n",
    "    def get_dataset(batch_size):\n",
    "        '''Get the dataset.'''\n",
    "        retain_ds = HiddenDataset(split='retain')\n",
    "        forget_ds = HiddenDataset(split='forget')\n",
    "        val_ds = HiddenDataset(split='validation')\n",
    "\n",
    "        retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True, generator=Gr)\n",
    "        forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True, generator=Gf)\n",
    "        validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=Gv)\n",
    "        #retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True)\n",
    "        #forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True)\n",
    "        #validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        return retain_loader, forget_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1083a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.105990Z",
     "iopub.status.busy": "2023-12-01T08:22:42.105740Z",
     "iopub.status.idle": "2023-12-01T08:22:42.110338Z",
     "shell.execute_reply": "2023-12-01T08:22:42.109659Z"
    },
    "papermill": {
     "duration": 0.010999,
     "end_time": "2023-12-01T08:22:42.112114",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.101115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "@contextmanager\n",
    "def stopwatch(name='STOPWATCH'):\n",
    "    s = time.time()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        print(f\"{name}: {time.time()-s} seconds passed\")\n",
    "        \n",
    "# for test\n",
    "# with stopwatch():\n",
    "#     for i in range(5):\n",
    "#         time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e438b59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.120890Z",
     "iopub.status.busy": "2023-12-01T08:22:42.120656Z",
     "iopub.status.idle": "2023-12-01T08:22:42.137120Z",
     "shell.execute_reply": "2023-12-01T08:22:42.136376Z"
    },
    "papermill": {
     "duration": 0.02312,
     "end_time": "2023-12-01T08:22:42.139021",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.115901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
    "def kl_loss_sym(x,y):\n",
    "    kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "    return kl_loss(nn.LogSoftmax(dim=-1)(x),y)\n",
    "def unlearning(\n",
    "        net,\n",
    "        retain_loader,\n",
    "        forget_loader,\n",
    "        val_loader,\n",
    "):\n",
    "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
    "    print('-----------------------------------')\n",
    "    epochs = 8\n",
    "    retain_bs = 256\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.005,\n",
    "                          momentum=0.9, weight_decay=0)\n",
    "    optimizer_retain = optim.SGD(net.parameters(), lr=0.001*retain_bs/64, momentum=0.9, weight_decay=1e-2)\n",
    "    ##the learning rate is associated with the batchsize we used\n",
    "    optimizer_forget = optim.SGD(net.parameters(), lr=3e-4, momentum=0.9, weight_decay=0)\n",
    "    total_step = int(len(forget_loader)*epochs)\n",
    "    retain_ld = DataLoader(retain_loader.dataset, batch_size=retain_bs, shuffle=True)\n",
    "    retain_ld4fgt = DataLoader(retain_loader.dataset, batch_size=256, shuffle=True)\n",
    "    scheduler = CosineAnnealingLR(optimizer_forget, T_max=total_step, eta_min=1e-6)\n",
    "    if USE_MOCK: ##Use some Local Metric as reference\n",
    "        net.eval()\n",
    "        print('Forget')\n",
    "        evaluation(net, forget_loader, criterion)\n",
    "        print('Valid')\n",
    "        evaluation(net, validation_loader, criterion)\n",
    "    net.train()\n",
    "    for sample in forget_loader: ##First Stage \n",
    "        inputs = sample[\"image\"]\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        uniform_label = torch.ones_like(outputs).to(DEVICE) / outputs.shape[1] ##uniform pseudo label\n",
    "        loss = kl_loss_sym(outputs, uniform_label) ##optimize the distance between logits and pseudo labels\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if USE_MOCK:\n",
    "        print('Forget')\n",
    "        evaluation(net,forget_loader,criterion)\n",
    "        print('Valid')\n",
    "        evaluation(net, validation_loader,criterion)\n",
    "        print(f'epoch={epochs} and retain batch_sz={retain_bs}')\n",
    "    net.train()\n",
    "    for ep in range(epochs): ##Second Stage \n",
    "        net.train()\n",
    "        for sample_forget, sample_retain in zip(forget_loader, retain_ld4fgt):##Forget Round\n",
    "            t = 1.15 ##temperature coefficient\n",
    "            inputs_forget,inputs_retain = sample_forget[\"image\"],sample_retain['image']\n",
    "            inputs_forget, inputs_retain = inputs_forget.to(DEVICE), inputs_retain.to(DEVICE)\n",
    "            optimizer_forget.zero_grad()\n",
    "            outputs_forget,outputs_retain = net(inputs_forget),net(inputs_retain).detach()\n",
    "            loss = (-1 * nn.LogSoftmax(dim=-1)(outputs_forget @ outputs_retain.T/t)).mean() ##Contrastive Learning loss\n",
    "            loss.backward()\n",
    "            optimizer_forget.step()\n",
    "            scheduler.step()\n",
    "        for sample in retain_ld: ##Retain Round\n",
    "            inputs, labels = sample[\"image\"],sample[\"age_group\"]\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer_retain.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_retain.step()\n",
    "        if USE_MOCK: \n",
    "            print(f'epoch {ep}:')\n",
    "            print('Retain')\n",
    "            evaluation(net, retain_ld, criterion)\n",
    "            print('Forget')\n",
    "            evaluation(net, forget_loader, criterion)\n",
    "            print('Valid')\n",
    "            evaluation(net, validation_loader, criterion)\n",
    "    print('-----------------------------------')\n",
    "    return net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0103b9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.147773Z",
     "iopub.status.busy": "2023-12-01T08:22:42.147509Z",
     "iopub.status.idle": "2023-12-01T08:22:42.153940Z",
     "shell.execute_reply": "2023-12-01T08:22:42.153181Z"
    },
    "papermill": {
     "duration": 0.012903,
     "end_time": "2023-12-01T08:22:42.155849",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.142946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(net, dataloader, criterion, device = 'cuda'): ##evaluation function\n",
    "    net.eval()\n",
    "    total_samp = 0\n",
    "    total_acc = 0\n",
    "    total_loss = 0.0\n",
    "    for sample in dataloader:\n",
    "        images, labels = sample['image'].to(device), sample['age_group'].to(device)\n",
    "        _pred = net(images)\n",
    "        total_samp+=len(labels)\n",
    "        #print(f'total_samp={total_samp}')\n",
    "        loss = criterion(_pred, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_acc+=(_pred.max(1)[1] == labels).float().sum().item()\n",
    "        #print(f'total_acc={total_acc}')\n",
    "    #print(f'total_sample={total_samp}')\n",
    "    mean_loss = total_loss / len(dataloader)\n",
    "    mean_acc = total_acc/total_samp\n",
    "    print(f'loss={mean_loss}')\n",
    "    print(f'acc={mean_acc}')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a910624c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T08:22:42.165082Z",
     "iopub.status.busy": "2023-12-01T08:22:42.164791Z",
     "iopub.status.idle": "2023-12-01T08:22:42.184160Z",
     "shell.execute_reply": "2023-12-01T08:22:42.183440Z"
    },
    "papermill": {
     "duration": 0.026069,
     "end_time": "2023-12-01T08:22:42.186035",
     "exception": false,
     "start_time": "2023-12-01T08:22:42.159966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if USE_MOCK:\n",
    "    \n",
    "    # NOTE: Almost same as the original codes\n",
    "    \n",
    "    # Download\n",
    "    if not os.path.exists(mock_model_path):\n",
    "        response = requests.get(\"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\")\n",
    "        open(mock_model_path, \"wb\").write(response.content)    \n",
    "    \n",
    "    os.makedirs('/kaggle/tmp', exist_ok=True)\n",
    "    retain_loader, forget_loader, validation_loader = get_dataset(64)\n",
    "    net = resnet18(weights=None, num_classes=10)\n",
    "    net.to(DEVICE)\n",
    "    for i in tqdm.trange(n_checkpoints):\n",
    "        net.load_state_dict(torch.load(mock_model_path))\n",
    "        net_ = unlearning(net, retain_loader, forget_loader, validation_loader)\n",
    "        state = net_.state_dict()\n",
    "        torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n",
    "\n",
    "    # Ensure that submission.zip will contain exactly 512 checkpoints \n",
    "    # (if this is not the case, an exception will be thrown).\n",
    "    unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
    "    if len(unlearned_ckpts) != n_checkpoints:\n",
    "        raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n",
    "\n",
    "    subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n",
    "    \n",
    "else:\n",
    "    if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n",
    "        # mock submission\n",
    "        subprocess.run('touch submission.zip', shell=True)\n",
    "    else:\n",
    "\n",
    "        # Note: it's really important to create the unlearned checkpoints outside of the working directory \n",
    "        # as otherwise this notebook may fail due to running out of disk space.\n",
    "        # The below code saves them in /kaggle/tmp to avoid that issue.\n",
    "\n",
    "        os.makedirs('/kaggle/tmp', exist_ok=True)\n",
    "        retain_loader, forget_loader, validation_loader = get_dataset(64)\n",
    "        net = resnet18(weights=None, num_classes=10)\n",
    "        net.to(DEVICE)\n",
    "        for i in range(512):\n",
    "            net.load_state_dict(torch.load('/kaggle/input/neurips-2023-machine-unlearning/original_model.pth'))\n",
    "            net_ = unlearning(net, retain_loader, forget_loader, validation_loader)\n",
    "            state = net_.state_dict()\n",
    "            torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n",
    "\n",
    "        # Ensure that submission.zip will contain exactly 512 checkpoints \n",
    "        # (if this is not the case, an exception will be thrown).\n",
    "        unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
    "        if len(unlearned_ckpts) != 512:\n",
    "            raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n",
    "\n",
    "        subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6535361,
     "sourceId": 56167,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30554,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.949532,
   "end_time": "2023-12-01T08:22:43.409567",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-01T08:22:34.460035",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
